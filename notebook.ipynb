{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd44ed55",
   "metadata": {},
   "source": [
    "### Practical Exam: Customer Purchase Prediction\n",
    "RetailTech Solutions is a fast-growing international e-commerce platform operating in over 20 countries across Europe, North America, and Asia. They specialize in fashion, electronics, and home goods, with a unique business model that combines traditional retail with a marketplace for independent sellers.\n",
    "\n",
    "The company has seen rapid growth. A key part of their success has been their data-driven approach to personalization. However, as they plan their expansion into new markets, they need to improve their ability to predict customer behavior.\n",
    "\n",
    "Their marketing team wants to predict which customers are most likely to make a purchase based on their browsing behavior.\n",
    "\n",
    "As an AI Engineer, you will help build this prediction system. Your work will directly impact RetailTech's growth strategy and their goal of increasing revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1902c965",
   "metadata": {},
   "source": [
    "The marketing team has collected customer session data in raw_customer_data.csv, but it contains missing values and inconsistencies that need to be addressed. Create a cleaned version of the dataframe:\n",
    "\n",
    "Start with the data in the file raw_customer_data.csv\n",
    "Your output should be a DataFrame named clean_data\n",
    "All column names and values should match the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f9b1a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the raw data\n",
    "df = pd.read_csv(\"raw_customer_data.csv\")\n",
    "\n",
    "# Handle missing values according to specifications\n",
    "df['time_spent'] = df['time_spent'].fillna(df['time_spent'].median())\n",
    "df['pages_viewed'] = df['pages_viewed'].fillna(df['pages_viewed'].mean())  # Removed rounding\n",
    "df['basket_value'] = df['basket_value'].fillna(0)\n",
    "df['device_type'] = df['device_type'].fillna(\"Unknown\")\n",
    "df['customer_type'] = df['customer_type'].fillna(\"New\")\n",
    "\n",
    "# Convert data types\n",
    "df['customer_id'] = df['customer_id'].astype(int)\n",
    "df['pages_viewed'] = df['pages_viewed'].astype(int)  # Still converting to int as pages viewed should be whole numbers\n",
    "\n",
    "# Create the cleaned dataframe\n",
    "clean_data = df.copy()\n",
    "\n",
    "# Verify no missing values remain\n",
    "assert clean_data.isna().sum().sum() == 0, \"There are still missing values in the data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb18e47",
   "metadata": {},
   "source": [
    "Task 2\n",
    "The pre-cleaned dataset model_data.csv needs to be prepared for our neural network. Create the model features:\n",
    "\n",
    "* Start with the data in the file model_data.csv\n",
    "* Scale numerical features (time_spent, pages_viewed, basket_value) to 0-1 range\n",
    "* Apply one-hot encoding to the categorical features (device_type, customer_type)\n",
    "* The column names should have the following format: variable_name_category_name (e.g., device_type_Desktop)\n",
    "* Your output should be a DataFrame named model_feature_set, with all column names from model_data.csv except for the columns where one-hot encoding was applied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the model data\n",
    "df = pd.read_csv(\"model_data.csv\")\n",
    "\n",
    "# Identify columns\n",
    "numerical_cols = ['time_spent', 'pages_viewed', 'basket_value']\n",
    "categorical_cols = ['device_type', 'customer_type']\n",
    "target_col = 'purchase'\n",
    "\n",
    "# Scale numerical features (0-1 range)\n",
    "scaler = MinMaxScaler()\n",
    "scaled_numerical = pd.DataFrame(\n",
    "    scaler.fit_transform(df[numerical_cols]), \n",
    "    columns=numerical_cols\n",
    ")\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoded_categorical = pd.get_dummies(\n",
    "    df[categorical_cols], \n",
    "    prefix=categorical_cols\n",
    ")\n",
    "\n",
    "# Combine features and drop original categorical columns\n",
    "model_feature_set = pd.concat([\n",
    "    df[['customer_id']],  # Keep customer_id\n",
    "    scaled_numerical,\n",
    "    encoded_categorical,\n",
    "    df[target_col]  # Keep target variable\n",
    "], axis=1)\n",
    "\n",
    "# Verify all original categorical columns are gone\n",
    "assert all(col not in model_feature_set.columns for col in categorical_cols), \"Original categorical columns still exist\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7c0291",
   "metadata": {},
   "source": [
    "Task 3\n",
    "Now that all preparatory work has been done, create and train a neural network that would allow the company to predict purchases.\n",
    "\n",
    "* Using PyTorch, create a network with:\n",
    "    * At least one hidden layer with 8 units\n",
    "    * ReLU activation for hidden layer\n",
    "    * Sigmoid activation for the output layer\n",
    "* Using the prepared features in input_model_features.csv, train the model to predict purchases.\n",
    "* Use the validation dataset validation_features.csv to predict new values based on the trained model.\n",
    "* Your model should be named purchase_model and your output should be a DataFrame named validation_predictions with columns customer_id and purchase. The purchase column must be your predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 0.7867\n",
      "Epoch 20/50, Loss: 0.5926\n",
      "Epoch 30/50, Loss: 0.3489\n",
      "Epoch 40/50, Loss: 0.5754\n",
      "Epoch 50/50, Loss: 0.4622\n",
      "Validation Accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prepare data (using output from Task 2)\n",
    "X = model_feature_set.drop(columns=['customer_id', 'purchase']).values.astype('float32')\n",
    "y = model_feature_set['purchase'].values.astype('float32')\n",
    "\n",
    "# Split into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(X_train), \n",
    "    torch.tensor(y_train).unsqueeze(1)\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define the model\n",
    "class PurchaseModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(PurchaseModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(8, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "input_dim = X_train.shape[1]\n",
    "purchase_model = PurchaseModel(input_dim)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(purchase_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = purchase_model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Print training progress\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# Validation\n",
    "with torch.no_grad():\n",
    "    val_tensor = torch.tensor(X_val)\n",
    "    predictions = purchase_model(val_tensor).numpy().flatten()\n",
    "    predicted_labels = (predictions >= 0.5).astype(int)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_val, predicted_labels)\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Load validation features (as per task instructions)\n",
    "val_df = pd.read_csv('validation_features.csv')\n",
    "X_validation = val_df.drop(columns=['customer_id']).values.astype('float32')\n",
    "customer_ids = val_df['customer_id'].values\n",
    "\n",
    "# Make predictions on the provided validation set\n",
    "with torch.no_grad():\n",
    "    val_tensor = torch.tensor(X_validation)\n",
    "    predictions = purchase_model(val_tensor).numpy().flatten()\n",
    "    predicted_labels = (predictions >= 0.5).astype(int)\n",
    "\n",
    "# Create final output DataFrame\n",
    "validation_predictions = pd.DataFrame({\n",
    "    'customer_id': customer_ids,\n",
    "    'purchase': predicted_labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
